#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, csv, warnings, re
from urllib.parse import urlparse
import numpy as np
import awkward as ak
import uproot
import fsspec
from coffea.nanoevents.methods import vector as vector_methods

# Enable coffea vector behavior
ak.behavior.update(vector_methods.behavior)
warnings.filterwarnings("ignore", message="The value of the smallest subnormal")

INPUT_FILES = (
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/ST_tW_top_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/18ulsttw5fnohad/250809_061204/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/18ultthad/250809_061234/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/18ulttsl/250817_125832/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TT_Mtt-1000toInf_TuneCP5_13TeV-powheg-pythia8/18ulttmtt1000/250817_125624/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TT_Mtt-700to1000_TuneCP5_13TeV-powheg-pythia8/18ulttmtt700/250809_061337/000*/*.root",
    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/WJetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/18ulwjln/250809_061438/000*/*.root",
)

TREE = "Dumper/GlobalFrame"
CSV_PATH = "quantiles.csv"
OUTPUT_DIR = "."
STEP_SIZE = "50 MB"
GENWEIGHT_MAX = 1e6
OUTLIER_RATIO = 100.0  # drop if |genWeight| > OUTLIER_RATIO * median(|genWeight|) in sample

CONFIG = {
    "objects": {
        "ak8": {
            "branches": {"pt": "ak8_pt", "eta": "ak8_eta", "phi": "ak8_phi", "mass": "ak8_msd"},
            "id_var": "ak8_probRawHbb",
            "base_pt_csv": "ak8_pt"
        },
    },
    "pair_recipe": "ak8+ak8",
}

def read_csv_thresholds(csv_path):
    thresholds = {}
    with open(csv_path, "r") as f:
        for row in csv.DictReader(f):
            var = row["variable"].strip()
            pct = row["percentile"].strip()
            label = f"p{int(float(pct))}" if pct.isdigit() else pct
            thresholds.setdefault(var, []).append((label, float(row["value"])))
    
    for var in thresholds:
        thresholds[var].sort(key=lambda x: int(x[0][1:]) if x[0].startswith("p") else 0)
    return thresholds

def get_sample_tag(xrd_path):
    parts = urlparse(xrd_path).path.strip("/").split("/")
    if "user" in parts:
        idx = parts.index("user")
        if idx + 2 < len(parts):
            return parts[idx + 2]
    return parts[-5] if len(parts) >= 5 else "sample"

def expand_files(pattern):
    url = urlparse(pattern)
    host = url.netloc
    if not host:
        raise ValueError(f"Pattern must start with root://<host>: {pattern}")
    
    fs = fsspec.filesystem("root", hostid=host)
    matches = fs.glob(url.path)
    return [f"root://{host}{path}" for path in matches]

def process_sample(sample_name, files, thresholds, base_pt_cut, output_path):
    
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    
    # Branches to load per chunk
    branches = [
        "ak8_pt", "ak8_eta", "ak8_phi", "ak8_msd",
        "ak8_probRawHbb", "genWeight"
    ]

    # ---------- Pass 1: compute sample median of |genWeight| (after GENWEIGHT_MAX filter)
    abs_genw_values = []
    total_seen_events = 0
    for file_uri in files:
        try:
            with uproot.open(file_uri) as rf:
                tree = rf[TREE]
                for arrays in tree.iterate(expressions=branches, step_size=STEP_SIZE, library="ak"):
                    genw = ak.to_numpy(arrays["genWeight"]).astype(np.float64, copy=False)
                    valid_mask = np.abs(genw) <= GENWEIGHT_MAX
                    genw_valid = np.abs(genw[valid_mask])
                    if genw_valid.size:
                        abs_genw_values.append(genw_valid)
                        total_seen_events += genw_valid.size
        except Exception:
            continue
    if abs_genw_values:
        median_abs_genw = float(np.median(np.concatenate(abs_genw_values)))
    else:
        median_abs_genw = 0.0
    # Guard against zero median (e.g., all zeros); in that case, skip outlier filtering
    apply_outlier_filter = median_abs_genw > 0.0
    outlier_threshold = OUTLIER_RATIO * median_abs_genw if apply_outlier_filter else None

    # ---------- Pass 2: write filtered outputs
    with uproot.recreate(output_path) as fout:
        writers = {
            label: fout.mktree(label, {"mass": np.float32, "genw": np.float32})
            for label, _ in thresholds
        }
        
        sumw_total = 0.0
        n_total = 0
        n_filtered_genmax = 0
        n_filtered_outlier = 0
        
        for i, file_uri in enumerate(files, 1):
            file_sumw = 0.0
            file_events = 0
            file_f_genmax = 0
            file_f_outlier = 0
            
            try:
                with uproot.open(file_uri) as rf:
                    tree = rf[TREE]
                    
                    for arrays in tree.iterate(expressions=branches, step_size=STEP_SIZE, library="ak"):
                        genw = ak.to_numpy(arrays["genWeight"]).astype(np.float64, copy=False)
                        valid_mask = np.abs(genw) <= GENWEIGHT_MAX
                        file_f_genmax += int(np.sum(~valid_mask))
                        
                        # Apply GENWEIGHT_MAX filter to all arrays first
                        for key in arrays.fields:
                            arrays[key] = arrays[key][valid_mask]
                        genw = genw[valid_mask]
                        
                        # Apply outlier filter relative to sample median
                        if apply_outlier_filter:
                            out_mask = np.abs(genw) <= outlier_threshold
                            file_f_outlier += int(np.sum(~out_mask))
                            for key in arrays.fields:
                                arrays[key] = arrays[key][out_mask]
                            genw = genw[out_mask]
                        
                        # Update per-file aggregates
                        file_sumw += float(np.sum(genw))
                        file_events += int(len(genw))
                        
                        # Build jets and apply selections
                        jets = ak.zip({
                            "pt": arrays["ak8_pt"],
                            "eta": arrays["ak8_eta"],
                            "phi": arrays["ak8_phi"],
                            "mass": arrays["ak8_msd"]
                        }, with_name="PtEtaPhiMLorentzVector")
                        
                        if base_pt_cut is not None:
                            jets = jets[jets.pt > base_pt_cut]
                        
                        id_score = arrays["ak8_probRawHbb"]
                        if base_pt_cut is not None:
                            id_score = id_score[arrays["ak8_pt"] > base_pt_cut]
                        
                        for label, threshold in thresholds:
                            selected_jets = jets[id_score > threshold]
                            evt_mask = ak.num(selected_jets) >= 2
                            if not ak.any(evt_mask):
                                continue
                            selected_jets = selected_jets[evt_mask]
                            sorted_jets = selected_jets[ak.argsort(selected_jets.pt, axis=1, ascending=False)]
                            jet1 = sorted_jets[:, 0]
                            jet2 = sorted_jets[:, 1]
                            mass = (jet1 + jet2).mass
                            mass_array = ak.to_numpy(mass).astype(np.float32)
                            genw_array = genw[evt_mask].astype(np.float32)
                            writers[label].extend({
                                "mass": mass_array,
                                "genw": genw_array
                            })
                
                file_name = file_uri.split("/")[-1]
                msg = f"  [{i}/{len(files)}] {file_name}: events={file_events}, sumw={file_sumw:.2e}"
                if file_f_genmax > 0:
                    msg += f", filtered_genmax={file_f_genmax}"
                if file_f_outlier > 0:
                    msg += f", filtered_outlier={file_f_outlier}"
                print(msg)
                
                # Update sample totals once per file
                sumw_total += file_sumw
                n_total += file_events
                n_filtered_genmax += file_f_genmax
                n_filtered_outlier += file_f_outlier
                
            except Exception as e:
                file_name = file_uri.split("/")[-1]
                print(f"  [{i}/{len(files)}] {file_name}: ERROR - {e}")
                continue
        
        fout["meta"] = {"sumw_total": np.array([sumw_total], dtype=np.float64)}
        
        print(f"\n[SUMMARY] {sample_name}:")
        if n_filtered_genmax > 0:
            print(f"  - Filtered {n_filtered_genmax} events with |genWeight| > {GENWEIGHT_MAX}")
        if apply_outlier_filter and n_filtered_outlier > 0:
            print(f"  - Filtered {n_filtered_outlier} events with |genWeight|/median > {OUTLIER_RATIO:.0f} (median|w|={median_abs_genw:.3g})")
        elif not apply_outlier_filter:
            print("  - Outlier filter skipped (median |genWeight| is 0)")
        print(f"  - Valid events: {n_total}")
        print(f"  - Total sumw: {sumw_total:.6g}")
    
    print(f"[INFO] Saved to: {os.path.abspath(output_path)}")

print("="*60)
print(f"Starting mass calculation with genWeight filtering and outlier suppression")
print(f"Max |genWeight| = {GENWEIGHT_MAX}, outlier ratio = {OUTLIER_RATIO}x median |w|")
print("="*60)

csv_data = read_csv_thresholds(CSV_PATH)
id_var = CONFIG["objects"]["ak8"]["id_var"]

if id_var not in csv_data:
    raise ValueError(f"No thresholds found for {id_var} in {CSV_PATH}")

thresholds = csv_data[id_var]
print(f"\n[CONFIG] ID variable: {id_var}")
print(f"[CONFIG] Thresholds: {thresholds}")

base_pt_cut = None
if "base_pt_csv" in CONFIG["objects"]["ak8"]:
    pt_var = CONFIG["objects"]["ak8"]["base_pt_csv"]
    if pt_var in csv_data:
        base_pt_cut = max(val for _, val in csv_data[pt_var])
        print(f"[CONFIG] Base pt cut: {base_pt_cut} GeV")

all_samples = []
for pattern in INPUT_FILES:
    files = expand_files(pattern)
    if not files:
        print(f"[WARN] No files matched: {pattern}")
        continue
    
    sample_tag = get_sample_tag(files[0])
    all_samples.append({
        "name": sample_tag,
        "files": files
    })

if not all_samples:
    raise RuntimeError("No input files found!")

print(f"\n[INFO] Found {len(all_samples)} samples")

for sample in all_samples:
    print(f"\n{'='*60}")
    print(f"Processing: {sample['name']} ({len(sample['files'])} files)")
    print(f"{'='*60}")
    
    output_path = os.path.join(OUTPUT_DIR, f"{sample['name']}.root")
    
    process_sample(
        sample_name=sample["name"],
        files=sample["files"],
        thresholds=thresholds,
        base_pt_cut=base_pt_cut,
        output_path=output_path
    )

print("All done!")
