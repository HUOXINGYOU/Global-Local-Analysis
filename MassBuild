#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, csv, warnings, re
from urllib.parse import urlparse
import numpy as np
import awkward as ak
import uproot
import fsspec
from coffea.nanoevents.methods import vector as vector_methods

# Enable coffea vector behavior
ak.behavior.update(vector_methods.behavior)
warnings.filterwarnings("ignore", message="The value of the smallest subnormal")

INPUT_FILES = (
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/ST_tW_top_5f_NoFullyHadronicDecays_TuneCP5_13TeV-powheg-pythia8/18ulsttw5fnohad/250809_061204/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TTToHadronic_TuneCP5_13TeV-powheg-pythia8/18ultthad/250809_061234/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TTToSemiLeptonic_TuneCP5_13TeV-powheg-pythia8/18ulttsl/250817_125832/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TT_Mtt-1000toInf_TuneCP5_13TeV-powheg-pythia8/18ulttmtt1000/250817_125624/000*/*.root",
#    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/TT_Mtt-700to1000_TuneCP5_13TeV-powheg-pythia8/18ulttmtt700/250809_061337/000*/*.root",
    "root://cceos.ihep.ac.cn///eos/ihep/cms/store/user/yipin/WJetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8/18ulwjln/250809_061438/000*/*.root",
)

TREE = "Dumper/GlobalFrame"
CSV_PATH = "quantiles.csv"
OUTPUT_DIR = "."
STEP_SIZE = "50 MB"
GENWEIGHT_MAX = 1e6

CONFIG = {
    "objects": {
        "ak8": {
            "branches": {"pt": "ak8_pt", "eta": "ak8_eta", "phi": "ak8_phi", "mass": "ak8_msd"},
            "id_var": "ak8_probRawHbb",
            "base_pt_csv": "ak8_pt"
        },
    },
    "pair_recipe": "ak8+ak8",
}

def read_csv_thresholds(csv_path):
    thresholds = {}
    with open(csv_path, "r") as f:
        for row in csv.DictReader(f):
            var = row["variable"].strip()
            pct = row["percentile"].strip()
            label = f"p{int(float(pct))}" if pct.isdigit() else pct
            thresholds.setdefault(var, []).append((label, float(row["value"])))
    
    for var in thresholds:
        thresholds[var].sort(key=lambda x: int(x[0][1:]) if x[0].startswith("p") else 0)
    return thresholds

def get_sample_tag(xrd_path):
    parts = urlparse(xrd_path).path.strip("/").split("/")
    if "user" in parts:
        idx = parts.index("user")
        if idx + 2 < len(parts):
            return parts[idx + 2]
    return parts[-5] if len(parts) >= 5 else "sample"

def expand_files(pattern):
    url = urlparse(pattern)
    host = url.netloc
    if not host:
        raise ValueError(f"Pattern must start with root://<host>: {pattern}")
    
    fs = fsspec.filesystem("root", hostid=host)
    matches = fs.glob(url.path)
    return [f"root://{host}{path}" for path in matches]

def process_sample(sample_name, files, thresholds, base_pt_cut, output_path):
    
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    
    with uproot.recreate(output_path) as fout:
        writers = {
            label: fout.mktree(label, {"mass": np.float32, "genw": np.float32})
            for label, _ in thresholds
        }
        
        sumw_total = 0.0
        n_total = 0
        n_filtered = 0
        
        branches = ["ak8_pt", "ak8_eta", "ak8_phi", "ak8_msd", 
                   "ak8_probRawHbb", "genWeight"]
        
        for i, file_uri in enumerate(files, 1):
            file_sumw = 0.0
            file_events = 0
            file_filtered = 0
            
            try:
                with uproot.open(file_uri) as rf:
                    tree = rf[TREE]
                    
                    for arrays in tree.iterate(expressions=branches, 
                                              step_size=STEP_SIZE, 
                                              library="ak"):
                        
                        genw = ak.to_numpy(arrays["genWeight"])
                        valid_mask = np.abs(genw) <= GENWEIGHT_MAX
                        file_filtered += np.sum(~valid_mask)
                        for key in arrays.fields:
                            arrays[key] = arrays[key][valid_mask]
                        genw = genw[valid_mask]
                        
                        file_sumw += float(np.sum(genw))
                        file_events += len(genw)
                        sumw_total += file_sumw
                        n_total += file_events
                        n_filtered += file_filtered
                        
                        jets = ak.zip({
                            "pt": arrays["ak8_pt"],
                            "eta": arrays["ak8_eta"],
                            "phi": arrays["ak8_phi"],
                            "mass": arrays["ak8_msd"]
                        }, with_name="PtEtaPhiMLorentzVector")
                        
                        if base_pt_cut is not None:
                            jets = jets[jets.pt > base_pt_cut]
                        
                        id_score = arrays["ak8_probRawHbb"]
                        if base_pt_cut is not None:
                            id_score = id_score[arrays["ak8_pt"] > base_pt_cut]
                        
                        for label, threshold in thresholds:
                            selected_jets = jets[id_score > threshold]
                            evt_mask = ak.num(selected_jets) >= 2
                            
                            if not ak.any(evt_mask):
                                continue
                            
                            selected_jets = selected_jets[evt_mask]
                            sorted_jets = selected_jets[ak.argsort(selected_jets.pt, 
                                                                  axis=1, 
                                                                  ascending=False)]
                            jet1 = sorted_jets[:, 0]
                            jet2 = sorted_jets[:, 1]
                            
                            mass = (jet1 + jet2).mass
                            mass_array = ak.to_numpy(mass).astype(np.float32)
                            genw_array = genw[evt_mask].astype(np.float32)
                            
                            writers[label].extend({
                                "mass": mass_array,
                                "genw": genw_array
                            })
                
                file_name = file_uri.split("/")[-1]
                if file_filtered > 0:
                    print(f"  [{i}/{len(files)}] {file_name}: events={file_events}, filtered={file_filtered}, sumw={file_sumw:.2e}")
                else:
                    print(f"  [{i}/{len(files)}] {file_name}: events={file_events}, sumw={file_sumw:.2e}")
                    
            except Exception as e:
                file_name = file_uri.split("/")[-1]
                print(f"  [{i}/{len(files)}] {file_name}: ERROR - {e}")
                continue
        
        fout["meta"] = {"sumw_total": np.array([sumw_total], dtype=np.float64)}
        
        print(f"\n[SUMMARY] {sample_name}:")
        if n_filtered > 0:
            print(f"  - Filtered {n_filtered} events with |genWeight| > {GENWEIGHT_MAX}")
        print(f"  - Valid events: {n_total}")
        print(f"  - Total sumw: {sumw_total:.6g}")
    
    print(f"[INFO] Saved to: {os.path.abspath(output_path)}")

print("="*60)
print(f"Starting mass calculation with genWeight filtering")
print(f"Max |genWeight| = {GENWEIGHT_MAX}")
print("="*60)

csv_data = read_csv_thresholds(CSV_PATH)
id_var = CONFIG["objects"]["ak8"]["id_var"]

if id_var not in csv_data:
    raise ValueError(f"No thresholds found for {id_var} in {CSV_PATH}")

thresholds = csv_data[id_var]
print(f"\n[CONFIG] ID variable: {id_var}")
print(f"[CONFIG] Thresholds: {thresholds}")

base_pt_cut = None
if "base_pt_csv" in CONFIG["objects"]["ak8"]:
    pt_var = CONFIG["objects"]["ak8"]["base_pt_csv"]
    if pt_var in csv_data:
        base_pt_cut = max(val for _, val in csv_data[pt_var])
        print(f"[CONFIG] Base pt cut: {base_pt_cut} GeV")

all_samples = []
for pattern in INPUT_FILES:
    files = expand_files(pattern)
    if not files:
        print(f"[WARN] No files matched: {pattern}")
        continue
    
    sample_tag = get_sample_tag(files[0])
    all_samples.append({
        "name": sample_tag,
        "files": files
    })

if not all_samples:
    raise RuntimeError("No input files found!")

print(f"\n[INFO] Found {len(all_samples)} samples")

for sample in all_samples:
    print(f"\n{'='*60}")
    print(f"Processing: {sample['name']} ({len(sample['files'])} files)")
    print(f"{'='*60}")
    
    output_path = os.path.join(OUTPUT_DIR, f"{sample['name']}.root")
    
    process_sample(
        sample_name=sample["name"],
        files=sample["files"],
        thresholds=thresholds,
        base_pt_cut=base_pt_cut,
        output_path=output_path
    )

print("All done!")
